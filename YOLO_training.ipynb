{"cells":[{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9258,"status":"ok","timestamp":1669618998794,"user":{"displayName":"Muhammad Toqeer","userId":"11037238904036853143"},"user_tz":-300},"id":"wbvMlHd_QwMG","outputId":"fe2d3963-f52f-4f8f-820b-2cb64aa23d8a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 14184, done.\u001b[K\n","remote: Counting objects: 100% (124/124), done.\u001b[K\n","remote: Compressing objects: 100% (61/61), done.\u001b[K\n","remote: Total 14184 (delta 76), reused 95 (delta 63), pack-reused 14060\u001b[K\n","Receiving objects: 100% (14184/14184), 13.60 MiB | 12.60 MiB/s, done.\n","Resolving deltas: 100% (9739/9739), done.\n","/content/yolov5/yolov5/yolov5\n"]}],"source":["!git clone https://github.com/ultralytics/yolov5  # clone\n","%cd yolov5\n","%pip install -qr requirements.txt  # install\n","%pip install -q roboflow\n","import numpy as np\n","\n","import torch\n","import os\n","from IPython.display import Image, clear_output \n","\n"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1669618998794,"user":{"displayName":"Muhammad Toqeer","userId":"11037238904036853143"},"user_tz":-300},"id":"qbFZH1QSN8eX","outputId":"5361eb7a-47d6-40d0-c3cd-c1f37fe4f566"},"outputs":[{"output_type":"stream","name":"stdout","text":["upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5s&ref=ultralytics\n"]}],"source":["from roboflow import Roboflow\n","rf = Roboflow(model_format = 'yolov5s', notebook = 'ultralytics')"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"grdTJ1KEOeV9","executionInfo":{"status":"ok","timestamp":1669619027641,"user_tz":-300,"elapsed":9,"user":{"displayName":"Muhammad Toqeer","userId":"11037238904036853143"}}},"outputs":[],"source":["# setup environment \n","# os.environ['DATASET_DIRETORY'] = \"/content/datasets\""]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7903,"status":"ok","timestamp":1669619027640,"user":{"displayName":"Muhammad Toqeer","userId":"11037238904036853143"},"user_tz":-300},"id":"SNvn89EaO7nN","outputId":"5e769cba-92e2-4cd4-bc21-a8c9a1490b6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","Downloading Dataset Version Zip in data-annot-5 to yolov5pytorch: 100% [5374381 / 5374381] bytes\n"]},{"output_type":"stream","name":"stderr","text":["Extracting Dataset Version Zip to data-annot-5 in yolov5pytorch:: 100%|██████████| 538/538 [00:00<00:00, 977.37it/s]\n"]}],"source":["from roboflow import Roboflow\n","rf = Roboflow(api_key=\"kDFUi3tsyrFdbhoYlf7j\")\n","project = rf.workspace(\"yolo-hnlmq\").project(\"data-annot\")\n","dataset = project.version(5).download(\"yolov5\")"]},{"cell_type":"code","source":["# /content/yolov5"],"metadata":{"id":"UcuiwTkVyVcg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYOzyjffQZBV","outputId":"bb8f0698-087d-4a85-8bb1-a6c49af6b69f","executionInfo":{"status":"ok","timestamp":1669610666935,"user_tz":-300,"elapsed":703791,"user":{"displayName":"Muhammad Toqeer","userId":"11037238904036853143"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/data-annot-5/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-8-g350e8eb Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 81.1MB/s]\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n","100% 14.1M/14.1M [00:00<00:00, 289MB/s]\n","\n","Overriding model.yaml nc=80 with nc=4\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/data-annot-5/train/labels... 228 images, 4 backgrounds, 0 corrupt: 100% 228/228 [00:00<00:00, 1638.36it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/data-annot-5/train/labels.cache\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB ram): 100% 228/228 [00:01<00:00, 116.75it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/data-annot-5/valid/labels... 21 images, 0 backgrounds, 0 corrupt: 100% 21/21 [00:00<00:00, 577.15it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/data-annot-5/valid/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 21/21 [00:00<00:00, 34.04it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.00 anchors/target, 0.974 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 613 points...\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7926: 100% 1000/1000 [00:02<00:00, 475.51it/s]\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9935 best possible recall, 5.67 anchors past thr\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=1280, metric_all=0.372/0.794-mean/best, past_thr=0.482-mean: 199,197, 336,333, 984,159, 161,983, 1006,256, 262,984, 679,450, 474,903, 942,782\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n","Plotting labels to runs/train/exp/labels.jpg... \n","Image sizes 1280 train, 1280 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/49      14.4G     0.1128    0.08168    0.04638         18       1280: 100% 15/15 [00:18<00:00,  1.25s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.33s/it]\n","                   all         21         64    0.00382      0.391     0.0042    0.00116\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/49      13.7G     0.1005    0.05048    0.04444         13       1280: 100% 15/15 [00:11<00:00,  1.35it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.27it/s]\n","                   all         21         64     0.0057      0.563     0.0105    0.00267\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/49      13.7G    0.08749    0.04949    0.04312         13       1280: 100% 15/15 [00:11<00:00,  1.33it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.23it/s]\n","                   all         21         64    0.00958      0.576     0.0487     0.0147\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/49      13.7G    0.07617    0.04952    0.04159         13       1280: 100% 15/15 [00:11<00:00,  1.32it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.18it/s]\n","                   all         21         64    0.00813      0.594     0.0526     0.0162\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/49      13.7G     0.0698    0.05008    0.03995         19       1280: 100% 15/15 [00:11<00:00,  1.36it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.11it/s]\n","                   all         21         64    0.00531      0.447     0.0598     0.0125\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/49      13.7G    0.06625    0.05093     0.0385         11       1280: 100% 15/15 [00:10<00:00,  1.37it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.01s/it]\n","                   all         21         64    0.00408      0.461     0.0677     0.0156\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/49      13.7G    0.06457     0.0512    0.03969         13       1280: 100% 15/15 [00:10<00:00,  1.39it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.11it/s]\n","                   all         21         64    0.00744      0.684      0.184     0.0618\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/49      13.7G    0.06293    0.04646    0.03944         12       1280: 100% 15/15 [00:10<00:00,  1.37it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.15it/s]\n","                   all         21         64    0.00885      0.725     0.0695     0.0202\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/49      13.7G    0.06117    0.04908    0.03914         16       1280: 100% 15/15 [00:10<00:00,  1.38it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.03it/s]\n","                   all         21         64    0.00671      0.646     0.0693     0.0177\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/49      13.7G    0.05773    0.04766    0.03879         17       1280: 100% 15/15 [00:10<00:00,  1.38it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.35s/it]\n","                   all         21         64    0.00491      0.498     0.0845     0.0267\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/49      13.7G    0.05849    0.04856    0.03899         15       1280: 100% 15/15 [00:10<00:00,  1.37it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.20it/s]\n","                   all         21         64    0.00612       0.53     0.0948     0.0304\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/49      13.7G    0.05575    0.05156    0.03709         17       1280: 100% 15/15 [00:11<00:00,  1.34it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.20s/it]\n","                   all         21         64    0.00562      0.548     0.0584     0.0253\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/49      13.7G    0.05154    0.05263    0.03782         12       1280: 100% 15/15 [00:11<00:00,  1.34it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.75s/it]\n","                   all         21         64     0.0067      0.584      0.103      0.033\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/49      13.7G    0.05331    0.05036    0.03719         13       1280: 100% 15/15 [00:11<00:00,  1.26it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.52s/it]\n","                   all         21         64     0.0448      0.519      0.122     0.0346\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/49      13.7G    0.04895    0.05226    0.03605         17       1280: 100% 15/15 [00:10<00:00,  1.39it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.15it/s]\n","                   all         21         64     0.0751      0.608      0.191     0.0497\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/49      13.7G    0.05167    0.05137    0.03738          9       1280: 100% 15/15 [00:10<00:00,  1.38it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.12it/s]\n","                   all         21         64      0.103      0.556      0.213     0.0752\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/49      13.7G    0.04691    0.05257    0.03598         21       1280: 100% 15/15 [00:11<00:00,  1.34it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.03it/s]\n","                   all         21         64      0.133      0.635       0.26     0.0958\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/49      13.7G    0.04914    0.05146    0.03644         10       1280: 100% 15/15 [00:11<00:00,  1.34it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.06s/it]\n","                   all         21         64      0.157      0.383      0.218     0.0839\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/49      13.7G    0.04894    0.04596    0.03448         18       1280: 100% 15/15 [00:11<00:00,  1.32it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.10s/it]\n","                   all         21         64      0.185      0.645      0.294      0.101\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/49      13.7G    0.04716    0.04712    0.03436         15       1280: 100% 15/15 [00:11<00:00,  1.34it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.10s/it]\n","                   all         21         64     0.0559      0.585      0.185     0.0455\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/49      13.7G    0.04746     0.0483    0.03522         14       1280: 100% 15/15 [00:10<00:00,  1.40it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.05it/s]\n","                   all         21         64      0.145      0.468      0.229     0.0809\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/49      13.7G    0.04802    0.04877    0.03533         10       1280: 100% 15/15 [00:10<00:00,  1.41it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.10it/s]\n","                   all         21         64      0.543       0.31      0.272      0.104\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/49      13.7G    0.04736    0.04952    0.03603         10       1280: 100% 15/15 [00:11<00:00,  1.36it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.22it/s]\n","                   all         21         64      0.532      0.294      0.285      0.127\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/49      13.7G    0.04453    0.04847    0.03269         14       1280: 100% 15/15 [00:10<00:00,  1.38it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.34it/s]\n","                   all         21         64      0.537      0.297      0.315      0.126\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/49      13.7G    0.04521    0.05448    0.03183         23       1280: 100% 15/15 [00:10<00:00,  1.39it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.24it/s]\n","                   all         21         64      0.559      0.389      0.379      0.162\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      25/49      13.7G    0.04456    0.04812    0.03397         14       1280: 100% 15/15 [00:10<00:00,  1.38it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.26it/s]\n","                   all         21         64      0.582       0.35      0.395      0.151\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      26/49      13.7G    0.04261    0.04544     0.0296          9       1280: 100% 15/15 [00:10<00:00,  1.37it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.11it/s]\n","                   all         21         64      0.516      0.371      0.338      0.151\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      27/49      13.7G    0.04214    0.05029    0.03374         10       1280: 100% 15/15 [00:10<00:00,  1.37it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.22it/s]\n","                   all         21         64      0.422      0.358      0.368      0.144\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      28/49      13.7G      0.042    0.05293     0.0327         20       1280: 100% 15/15 [00:10<00:00,  1.38it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.31it/s]\n","                   all         21         64      0.403      0.376      0.418      0.164\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      29/49      13.7G    0.04058     0.0449    0.03096          7       1280: 100% 15/15 [00:10<00:00,  1.38it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.20it/s]\n","                   all         21         64      0.425      0.377       0.39      0.163\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      30/49      13.7G    0.04054    0.04864    0.03196         10       1280: 100% 15/15 [00:10<00:00,  1.38it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.26it/s]\n","                   all         21         64      0.476      0.422      0.423      0.186\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      31/49      13.7G    0.03806     0.0474    0.03121         13       1280: 100% 15/15 [00:11<00:00,  1.36it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.24it/s]\n","                   all         21         64      0.445      0.379      0.405      0.162\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      32/49      13.7G    0.03691    0.04849     0.0317          9       1280: 100% 15/15 [00:10<00:00,  1.37it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.20it/s]\n","                   all         21         64      0.442      0.389      0.396      0.166\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      33/49      13.7G    0.03969     0.0446    0.03125         20       1280: 100% 15/15 [00:11<00:00,  1.35it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.16it/s]\n","                   all         21         64      0.429       0.36      0.395      0.158\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      34/49      13.7G    0.03873    0.04975     0.0312         15       1280: 100% 15/15 [00:11<00:00,  1.28it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.16it/s]\n","                   all         21         64      0.477      0.384      0.486      0.204\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      35/49      13.7G    0.03635    0.04918    0.03045         17       1280: 100% 15/15 [00:10<00:00,  1.37it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.36it/s]\n","                   all         21         64      0.476      0.484      0.488      0.199\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      36/49      13.7G    0.03805    0.04919    0.03069         10       1280: 100% 15/15 [00:10<00:00,  1.37it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.26it/s]\n","                   all         21         64      0.483      0.451      0.453      0.181\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      37/49      13.7G    0.03935    0.04804    0.03086         17       1280: 100% 15/15 [00:12<00:00,  1.19it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.20it/s]\n","                   all         21         64       0.42      0.434      0.411      0.167\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      38/49      13.7G    0.03879    0.04779     0.0313         14       1280: 100% 15/15 [00:11<00:00,  1.31it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.35it/s]\n","                   all         21         64      0.443      0.429      0.451       0.21\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      39/49      13.7G    0.03673    0.04696    0.02878         17       1280: 100% 15/15 [00:11<00:00,  1.35it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.14it/s]\n","                   all         21         64      0.457      0.446      0.452      0.195\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      40/49      13.7G    0.03675    0.04375     0.0305          6       1280: 100% 15/15 [00:10<00:00,  1.37it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.02it/s]\n","                   all         21         64       0.43      0.453      0.454       0.21\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      41/49      13.7G    0.03581    0.04531      0.031          9       1280: 100% 15/15 [00:11<00:00,  1.36it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.18it/s]\n","                   all         21         64      0.463      0.439      0.493      0.222\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      42/49      13.7G    0.03642    0.05065    0.03024         17       1280: 100% 15/15 [00:11<00:00,  1.35it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.25it/s]\n","                   all         21         64      0.457      0.508      0.469      0.208\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      43/49      13.7G    0.03575    0.04813    0.03155         15       1280: 100% 15/15 [00:11<00:00,  1.36it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.04it/s]\n","                   all         21         64      0.506      0.519      0.504      0.238\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      44/49      13.7G    0.03396    0.04892    0.03005         10       1280: 100% 15/15 [00:11<00:00,  1.36it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.26it/s]\n","                   all         21         64      0.476      0.504      0.526      0.234\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      45/49      13.7G    0.03555    0.04717     0.0313         18       1280: 100% 15/15 [00:11<00:00,  1.35it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.16it/s]\n","                   all         21         64      0.495      0.451      0.538      0.249\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      46/49      13.7G    0.03334    0.05163    0.02692         14       1280: 100% 15/15 [00:11<00:00,  1.33it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.41it/s]\n","                   all         21         64      0.473      0.409      0.522      0.247\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      47/49      13.7G    0.03207    0.04706    0.02923         14       1280: 100% 15/15 [00:11<00:00,  1.29it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.18it/s]\n","                   all         21         64      0.511      0.432      0.508      0.236\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      48/49      13.7G    0.03288    0.04683    0.02838         16       1280: 100% 15/15 [00:12<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.11s/it]\n","                   all         21         64      0.511      0.467      0.524      0.233\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      49/49      13.7G    0.03293    0.04516    0.02996         14       1280: 100% 15/15 [00:12<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.14it/s]\n","                   all         21         64      0.516      0.504      0.529      0.249\n","\n","50 epochs completed in 0.183 hours.\n","Optimizer stripped from runs/train/exp/weights/last.pt, 15.1MB\n","Optimizer stripped from runs/train/exp/weights/best.pt, 15.1MB\n","\n","Validating runs/train/exp/weights/best.pt...\n","Fusing layers... \n","Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.23it/s]\n","                   all         21         64      0.495      0.451      0.538      0.247\n","                erasor         21         16      0.121      0.125      0.226      0.101\n","                pencil         21         18      0.744      0.323      0.675      0.233\n","                 scale         21         11      0.666      0.724      0.781      0.382\n","              sharpner         21         19       0.45      0.632      0.469      0.274\n","Results saved to \u001b[1mruns/train/exp\u001b[0m\n"]}],"source":["# Train YOLOv5s on dataset for 25 epochs\n","!python train.py --batch 16 --epochs 50 --img 1280 --data /content/yolov5/data-annot-5/data.yaml  --weights yolov5s.pt --cache "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HNjMTal2Tshc"},"outputs":[],"source":["# # start tensorboard\n","# # launch after yiu have started training\n","# # logs saved in the folder \"runs\"\n","\n","\n","# %load_ext tensorboard\n","# %tensorboard --logdir runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10892,"status":"ok","timestamp":1669610677815,"user":{"displayName":"Muhammad Toqeer","userId":"11037238904036853143"},"user_tz":-300},"id":"NtS7lidcVJdt","outputId":"69b9977b-3613-4e95-8b53-ab4c4f36d461"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=/content/yolov5/data-annot-3/test/images/imge--17-_jpeg.rf.b2ed175cd66a65c45ce25838427277e2.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.05, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v7.0-8-g350e8eb Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n","Traceback (most recent call last):\n","  File \"detect.py\", line 259, in <module>\n","    main(opt)\n","  File \"detect.py\", line 254, in main\n","    run(**vars(opt))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"detect.py\", line 109, in run\n","    dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)\n","  File \"/content/yolov5/utils/dataloaders.py\", line 251, in __init__\n","    raise FileNotFoundError(f'{p} does not exist')\n","FileNotFoundError: /content/yolov5/data-annot-3/test/images/imge--17-_jpeg.rf.b2ed175cd66a65c45ce25838427277e2.jpg does not exist\n"]}],"source":["#Making Predictions\n","\n","# !python detect.py --weights runs/train/exp/weights/best.pt --conf 0.07 --source {dataset.location}/test/images\n","!python detect.py --weights runs/train/exp/weights/best.pt --conf 0.05 --source /content/yolov5/data-annot-3/test/images/imge--17-_jpeg.rf.b2ed175cd66a65c45ce25838427277e2.jpg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_dPMDBjAWXCn"},"outputs":[],"source":["# # display inference on all test images\n","# import glob\n","# from IPython.display import Image, display\n","# i = 0\n","# for imagename in glob.glob('/content/yolov5/runs/train/exp/*.jpg'):\n","#   i += 1\n","#   if i< 27:\n","#     display(Image(filename = imagename))\n","#     print(\"\\n\\n\\n\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12302,"status":"ok","timestamp":1669612297214,"user":{"displayName":"Muhammad Toqeer","userId":"11037238904036853143"},"user_tz":-300},"id":"_e_b4UpLgnKI","outputId":"eb2c5bf0-c822-4ee4-a5bc-57f6745cbfbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=/content/download.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.05, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v7.0-8-g350e8eb Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n","Traceback (most recent call last):\n","  File \"detect.py\", line 259, in <module>\n","    main(opt)\n","  File \"detect.py\", line 254, in main\n","    run(**vars(opt))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"detect.py\", line 109, in run\n","    dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)\n","  File \"/content/yolov5/utils/dataloaders.py\", line 251, in __init__\n","    raise FileNotFoundError(f'{p} does not exist')\n","FileNotFoundError: /content/download.jpg does not exist\n"]}],"source":["!python detect.py --weights runs/train/exp/weights/best.pt --conf 0.05 --source /content/download.jpg"]},{"cell_type":"markdown","metadata":{"id":"j_-SCiMLnos5"},"source":["Save the Training Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-4Ac56m0nnU1","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1669613139983,"user_tz":-300,"elapsed":886,"user":{"displayName":"Muhammad Toqeer","userId":"11037238904036853143"}},"outputId":"10f89eac-9c53-4607-b650-4d863ce0abd4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_ae10d6aa-3b46-4670-91e4-11ad5ad87385\", \"yolov5\", 4096)"]},"metadata":{}}],"source":["#exporting models weights\n","\n","from google.colab import files\n","files.download(\"/content/yolov5\")"]},{"cell_type":"code","source":["from PIL import Image\n","\n","basewidth = 128\n","img = Image.open('/content/WhatsApp Image 2022-11-12 at 4.06.59 PM (1).jpeg')\n","img = img.resize((128, 128), Image.ANTIALIAS)\n","np.array(img).shape"],"metadata":{"id":"UG13CB-BHtzB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Calculate total bill for inference "],"metadata":{"id":"N6bBchEVjGvD"}},{"cell_type":"code","source":["import cv2\n","# !pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt\n","\n","def calculate_bill(path):\n","    model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/yolov5/runs/train/exp/weights/best.pt', force_reload=True )\n","    frame = cv2.imread(path)\n","    model.conf = 0.025\n","    results = model(frame)\n","    TOTAL=0\n","    for i in results.pandas().xyxy[0]['class']:\n","        if i == 1: # Erasor\n","            TOTAL+=5\n","        elif i==2:# Pencil\n","            TOTAL+=20\n","        elif i==3: # Scale\n","            TOTAL+=10\n","        else: # Sharpner\n","            TOTAL+=5\n","\n","    return TOTAL"],"metadata":{"id":"NxZldFTYiPJJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!apt-get install swig cmake libopenmpi-dev zlib1g-dev xvfb x11-utils ghostscript ffmpeg -qq #remove -qq for full output\n","!pip install pyvirtualdisplay ghostscript"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lGga4B01vwFz","executionInfo":{"status":"ok","timestamp":1669615187445,"user_tz":-300,"elapsed":8095,"user":{"displayName":"Muhammad Toqeer","userId":"11037238904036853143"}},"outputId":"67757d9a-15a9-43c3-e283-80c903d56f58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/universe/x/xorg-server/xvfb_1.19.6-1ubuntu4.11_amd64.deb  404  Not Found [IP: 185.125.190.36 80]\n","E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (3.0)\n","Requirement already satisfied: ghostscript in /usr/local/lib/python3.7/dist-packages (0.7)\n","Requirement already satisfied: setuptools>=38.6.0 in /usr/local/lib/python3.7/dist-packages (from ghostscript) (57.4.0)\n"]}]},{"cell_type":"code","source":["import os\n","os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n","os.environ['DISPLAY'] = ':1'\n","from tkinter import *\n","from google.colab.patches import cv2_imshow\n","from google.colab import output\n","from PIL import Image"],"metadata":{"id":"on7FXthDw27-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"62xl9rwqqplG"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}